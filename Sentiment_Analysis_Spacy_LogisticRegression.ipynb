{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044f9c37",
   "metadata": {},
   "source": [
    "This code will help understanding text and its classification using spacy packages. All the preprocessing of the text will be done using Spacy packages. For training model, either spacy or skicit packages will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321a53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e7d01",
   "metadata": {},
   "source": [
    "Read the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d11935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  target\n",
      "0    If you like adult comedy cartoons, like South ...       1\n",
      "1    Bromwell High is a cartoon comedy. It ran at t...       1\n",
      "2    All the world's a stage and its people actors ...       1\n",
      "3    FUTZ is the only show preserved from the exper...       1\n",
      "4    I came in in the middle of this film so I had ...       1\n",
      "..                                                 ...     ...\n",
      "97   When a man who doesn't have Alzheimer's can't ...       0\n",
      "98   There are some nice shots in this film, it cat...       0\n",
      "99   A very cheesy and dull road movie, with the in...       0\n",
      "100  Three part \"horror\" film with some guy in a bo...       0\n",
      "101  Three part \"horror\" film with some guy in a bo...       0\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('input.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423ed61",
   "metadata": {},
   "source": [
    "Stop words are removed first and then lemmatization is applied by converting to root words if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c550dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "stop_words.add(\"in\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "df['text_no_stop'] = df['text']\n",
    "\n",
    "for text in df['text']:\n",
    "    words = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.text not in stop_words:\n",
    "            words.append(word.lemma_)\n",
    "            \n",
    "    \n",
    "    stop_word = re.sub(r'[^0-9a-zA-Z_//.]+',\" \",str(words))\n",
    "    \n",
    "       \n",
    "    df['text_no_stop'][count] = stop_word\n",
    "   \n",
    "    \n",
    "    count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575bf47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "      <td>1</td>\n",
       "      <td>if like adult comedy cartoon like South Park ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bromwell High cartoon comedy . it run time pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All the world's a stage and its people actors ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all world stage people actor like . who hell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>1</td>\n",
       "      <td>FUTZ preserve experimental theatre movement N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I came in in the middle of this film so I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I come middle film I idea credit title till I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>When a man who doesn't have Alzheimer's can't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>when man Alzheimer remember film probably wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>There are some nice shots in this film, it cat...</td>\n",
       "      <td>0</td>\n",
       "      <td>there nice shot film catch landscape beautifu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A very cheesy and dull road movie, with the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>a cheesy dull road movie intention hip modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Three part \"horror\" film with some guy in a bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>three horror film guy board house implore vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Three part \"horror\" film with some guy in a bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>three horror film guy board house implore vie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  \\\n",
       "0    If you like adult comedy cartoons, like South ...       1   \n",
       "1    Bromwell High is a cartoon comedy. It ran at t...       1   \n",
       "2    All the world's a stage and its people actors ...       1   \n",
       "3    FUTZ is the only show preserved from the exper...       1   \n",
       "4    I came in in the middle of this film so I had ...       1   \n",
       "..                                                 ...     ...   \n",
       "97   When a man who doesn't have Alzheimer's can't ...       0   \n",
       "98   There are some nice shots in this film, it cat...       0   \n",
       "99   A very cheesy and dull road movie, with the in...       0   \n",
       "100  Three part \"horror\" film with some guy in a bo...       0   \n",
       "101  Three part \"horror\" film with some guy in a bo...       0   \n",
       "\n",
       "                                          text_no_stop  \n",
       "0     if like adult comedy cartoon like South Park ...  \n",
       "1     Bromwell High cartoon comedy . it run time pr...  \n",
       "2     all world stage people actor like . who hell ...  \n",
       "3     FUTZ preserve experimental theatre movement N...  \n",
       "4     I come middle film I idea credit title till I...  \n",
       "..                                                 ...  \n",
       "97    when man Alzheimer remember film probably wor...  \n",
       "98    there nice shot film catch landscape beautifu...  \n",
       "99    a cheesy dull road movie intention hip modern...  \n",
       "100   three horror film guy board house implore vie...  \n",
       "101   three horror film guy board house implore vie...  \n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf50463",
   "metadata": {},
   "source": [
    "Token2Vec conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebbc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "df['word_vector'] = df['text']\n",
    "\n",
    "for text in df['text_no_stop']:\n",
    "    \n",
    "    word_vec=[]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "   \n",
    "    df['word_vector'][count] = doc.vector\n",
    "    \n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2b4ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 96)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Reshaping the Spacy Vector Matrix so that this vector matrix will be used for SCIKIT models\"\"\"\n",
    "vector_list = np.concatenate([nlp(i).vector.reshape(1,-1) for i in df['text_no_stop']])\n",
    "print(vector_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c6fabf",
   "metadata": {},
   "source": [
    "As the input is very small, instead of splitting the input data I am using different files for testing and scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "192b40da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What an inspiring movie, I laughed, cried and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is just a short comment but I stumbled on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My family and I have viewed this movie often o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a lovely heart warming television movie. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the odds of a \"Mermaid\" helium balloo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  What an inspiring movie, I laughed, cried and ...       1\n",
       "1  This is just a short comment but I stumbled on...       1\n",
       "2  My family and I have viewed this movie often o...       1\n",
       "3  What a lovely heart warming television movie. ...       1\n",
       "4  What are the odds of a \"Mermaid\" helium balloo...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e21f47",
   "metadata": {},
   "source": [
    "Do the same preprocessing step for test file as input file.  If large input file, this will be done at once and then split the input as train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074f6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "\n",
    "test['text_no_stop'] = test['text']\n",
    "\n",
    "for test_text in df['text']:\n",
    "    words = []\n",
    "    doc = nlp(test_text)\n",
    "    for word in doc:\n",
    "        if word.text not in stop_words:\n",
    "            words.append(word.lemma_)\n",
    "            \n",
    "    \n",
    "    stop_word = re.sub(r'[^0-9a-zA-Z_//.]+',\" \",str(words))\n",
    "    \n",
    "       \n",
    "    test['text_no_stop'][count] = stop_word\n",
    "   \n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7b3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "test['word_vector'] = test['text']\n",
    "\n",
    "for test_text in test['text_no_stop']:\n",
    "    \n",
    "    word_vec=[]\n",
    "    \n",
    "    doc = nlp(test_text)\n",
    "   \n",
    "    test['word_vector'][count] = doc.vector\n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c8d30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 96)\n"
     ]
    }
   ],
   "source": [
    "test_vector_list = np.concatenate([nlp(i).vector.reshape(1,-1) for i in test['text_no_stop']])\n",
    "print(test_vector_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223dbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fitting with the logistic Regression model\"\"\"\n",
    "model = LogisticRegression()\n",
    "clf = model.fit(vector_list,df['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901562fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predict the target for the test data and then score with the actuals\"\"\"\n",
    "\n",
    "y_test = np.array(test['target'])\n",
    "score = model.score(test_vector_list,y_test)\n",
    "y_hat = model.predict(test_vector_list)\n",
    "accuracy_score = metrics.accuracy_score(y_test,y_hat)\n",
    "print(score)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b77348",
   "metadata": {},
   "source": [
    "The above result is not really great accuracy as we have only 50% right result. Fine tuning the data by adding more preprocessing steps will give a higher accuracy.  And using large data will automatically increase the accuracy and reduce the loss.  This code is not really for optimization instead to understand how to preprocess using Spacy and then model with different libraries. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
